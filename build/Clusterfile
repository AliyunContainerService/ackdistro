apiVersion: sealer.cloud/v2
kind: Cluster
metadata:
  name: my-cluster
spec:
  image: ack:1.1
  env:
    - PodCIDR=172.24.0.0/24
    - SvcCIDR=10.96.0.0/16
    - Network=calico
    # ADP必装Addon，l-zero、open-local为内置Addon，不需要显示指定
    # 其他可选Addon：pvc-autoresizer,paralb,csi-minio,minio,csi-hostpath
    - Addons=cluster-operator,ack-node-problem-detector,etcd-backup
  ssh:
    passwd: Seadent123
    pk: /root/.ssh/id_rsa
    pkPasswd: xxx
    user: root
    port: "22"
  hosts:
    - ips: [ 172.16.0.49 ]
      roles: [ master ] # add role field to specify the node role
      env: # rewrite some nodes has different env config
        # 以下为必填参数：
        # EtcdDevice：集群元数据库etcd使用的块设备路径，建议分配一块独立块设备，每个Master上都需要；
        #   如果没有独立块设备，也可以配置为/，将直接使用系统盘，此时集群稳定性可能会受到节点上其他高IO应用的影响；
        - EtcdDevice=/dev/vdb
        # 容器管控分区大小
        - DockerRunDiskSize=200
        # K8s管控分区大小
        - KubeletRunDiskSize=200
        # StorageDevice：节点上容器管控及K8s管控数据使用的块设备路径，建议分配一块独立块设备，每个Master/Worker都需要；
        #   如果没有独立块设备，也可以配置为/，将直接使用系统盘，此时容器应用和节点上其他应用可能会互相影响，导致系统盘打满/容器驱逐等问题。
        #   至少需要(DockerRunDiskSize+KubeletRunDiskSize)GB空间，如果yoda的磁盘也是用这个磁盘，则下面的yodaDevice写/dev/vdd3，如果yoda有独立磁盘，则写独立磁盘名称
        - StorageDevice=/dev/vdc
        # YodaDevice: /dev/vdd3，每台host上为yoda准备的独立磁盘的设备名称，若有多块，以,分隔，如YodaDevice=/dev/vde,/dev/vdf
        - YodaDevice=/dev/vdc3
      ssh: # rewrite ssh config if some node has different passwd...
        user: root
        passwd: Seadent123
        port: "22"
    - ips: [ 172.16.0.50 ]
      roles: [ node ]
      env: # rewrite some nodes has different env config
        # 以下为必填参数：
        # EtcdDevice：集群元数据库etcd使用的块设备路径，建议分配一块独立块设备，每个Master上都需要；
        #   如果没有独立块设备，也可以配置为/，将直接使用系统盘，此时集群稳定性可能会受到节点上其他高IO应用的影响；
        - EtcdDevice=/dev/vdb
        # 容器管控分区大小
        - DockerRunDiskSize=200
        # K8s管控分区大小
        - KubeletRunDiskSize=200
        # StorageDevice：节点上容器管控及K8s管控数据使用的块设备路径，建议分配一块独立块设备，每个Master/Worker都需要；
        #   如果没有独立块设备，也可以配置为/，将直接使用系统盘，此时容器应用和节点上其他应用可能会互相影响，导致系统盘打满/容器驱逐等问题。
        #   至少需要(DockerRunDiskSize+KubeletRunDiskSize)GB空间，如果yoda的磁盘也是用这个磁盘，则下面的yodaDevice写/dev/vdd3，如果yoda有独立磁盘，则写独立磁盘名称
        - StorageDevice=/dev/vdc
        # YodaDevice: /dev/vdd3，每台host上为yoda准备的独立磁盘的设备名称，若有多块，以,分隔，如YodaDevice=/dev/vde,/dev/vdf
        - YodaDevice=/dev/vdc3
---
apiVersion: sealer.aliyun.com/v1alpha1
kind: Plugin
metadata:
  name: disk-init # Specify this plugin name,will dump in $rootfs/plugin dir.
spec:
  type: SHELL
  action: PreInit # PreInit PreInstall PostInstall
  'on': master
  data: |
    bash scripts/disk_init.sh -e"${EtcdDevice}" -d"${StorageDevice}" a"${DockerRunDiskSize}" b"${KubeletRunDiskSize}"
---
apiVersion: sealer.aliyun.com/v1alpha1
kind: Plugin
metadata:
  name: disk-init-rollback # Specify this plugin name,will dump in $rootfs/plugin dir.
spec:
  type: SHELL
  action: PostClean # PreInit PreInstall PostInstall
  'on': master
  data: |
    #exit 0
    bash scripts/disk_init_rollback.sh -e"${EtcdDevice}" -d"${StorageDevice}"
---
apiVersion: sealer.aliyun.com/v1alpha1
kind: Plugin
metadata:
  name: node-disk-init-rollback # Specify this plugin name,will dump in $rootfs/plugin dir.
spec:
  type: SHELL
  action: PostClean # PreInit PreInstall PostInstall
  'on': node
  data: |
    bash scripts/disk_init_rollback.sh -d"${StorageDevice}"
---
apiVersion: sealer.aliyun.com/v1alpha1
kind: Plugin
metadata:
  name: node-disk-init # Specify this plugin name,will dump in $rootfs/plugin dir.
spec:
  type: SHELL
  action: PreInit # PreInit PreInstall PostInstall
  'on': node
  data: |
    bash scripts/disk_init.sh -d"${StorageDevice}" a"${DockerRunDiskSize}" b"${KubeletRunDiskSize}"
---
apiVersion: sealer.aliyun.com/v1alpha1
kind: Plugin
metadata:
  name: preflight # Specify this plugin name,will dump in $rootfs/plugin dir.
spec:
  type: SHELL
  action: PreInit # PreInit PreInstall PostInstall
  'on': master0
  data: |
    trident preflight run -f /root/.sealer/my-cluster/Clusterfile --sealer
---
apiVersion: sealer.aliyun.com/v1alpha1
kind: Plugin
metadata:
  name: install-addons # Specify this plugin name,will dump in $rootfs/plugin dir.
spec:
  type: SHELL
  action: PostInstall # PreInit PreInstall PostInstall
  'on': master0
  data: |
    bash scripts/install_addons.sh ${Network} &&
    trident health-check
    if [ $? -eq 0 ];then
      exit 0
    fi
    echo "First time health check fail, try again"