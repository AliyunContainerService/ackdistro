apiVersion: v1
data:
  kernel-monitor.json: |
    {
        "plugin": "kmsg",
        "logPath": "/var/log/journal",
        "lookback": "5m",
        "bufferSize": 10,
        "source": "kernel-monitor",
        "conditions": [
            {
                "type": "KernelDeadlock",
                "reason": "KernelHasNoDeadlock",
                "message": "kernel has no deadlock"
            },
            {
                "type": "ReadonlyFilesystem",
                "reason": "FilesystemIsReadOnly",
                "message": "Filesystem is read-only"
            }
        ],
        "rules": [
            {
                "type": "temporary",
                "reason": "PodOOMKilling",
                "pattern": "Task in /kubepods.slice/(.+) killed as a result of limit of .*"
            },
            {
                "type": "temporary",
                "reason": "TaskHung",
                "pattern": "task \\S+:\\w+ blocked for more than \\w+ seconds\\."
            },
            {
                "type": "temporary",
                "reason": "UnregisterNetDevice",
                "pattern": "unregister_netdevice: waiting for \\w+ to become free. Usage count = \\d+"
            },
            {
                "type": "temporary",
                "reason": "KernelOops",
                "pattern": "BUG: unable to handle kernel NULL pointer dereference at .*"
            },
            {
                "type": "temporary",
                "reason": "KernelOops",
                "pattern": "divide error: 0000 \\[#\\d+\\] SMP"
            },
            {
                "type": "permanent",
                "condition": "KernelDeadlock",
                "reason": "AUFSUmountHung",
                "pattern": "task umount\\.aufs:\\w+ blocked for more than \\w+ seconds\\."
            },
            {
                "type": "permanent",
                "condition": "KernelDeadlock",
                "reason": "DockerHung",
                "pattern": "task docker:\\w+ blocked for more than \\w+ seconds\\."
            },
            {
                "type": "permanent",
                "condition": "ReadonlyFilesystem",
                "reason": "FilesystemIsReadOnly",
                "pattern": "Remounting filesystem read-only"
            }
        ]
    }
  docker-monitor.json: |
    {
        "plugin": "journald",
        "pluginConfig": {
            "source": "dockerd"
        },
        "logPath": "/var/log/journal",
        "lookback": "5m",
        "bufferSize": 10,
        "source": "docker-monitor",
        "conditions": [],
        "rules": [
            {
                "type": "temporary",
                "reason": "CorruptDockerImage",
                "pattern": "Error trying v2 registry: failed to register layer: rename /var/lib/docker/image/(.+) /var/lib/docker/image/(.+): directory not empty.*"
            }
        ]
    }

  ntp-problem-monitor.json: |
    {
      "plugin": "custom",
      "pluginConfig": {
        "invoke_interval": "600s",
        "timeout": "60s",
        "max_output_length": 80,
        "concurrency": 3,
        "enable_message_change_based_condition_update": false
      },
      "source": "ntp-custom-plugin-monitor",
      "conditions": [
        {
          "type": "NTPProblem",
          "reason": "NTPIsUp",
          "message": "ntp service is up"
        }
      ],
      "rules": [
        {
          "type": "temporary",
          "reason": "NTPIsDown",
          "path": "./config/plugin/check_ntp.sh",
          "timeout": "60s"
        },
        {
          "type": "permanent",
          "condition": "NTPProblem",
          "reason": "NTPIsDown",
          "path": "./config/plugin/check_ntp.sh",
          "timeout": "60s"
        }
      ]
    }
  check_ntp.sh: |
    #!/bin/bash

    # NOTE: THIS NTP SERVICE CHECK SCRIPT ASSUME THAT NTP SERVICE IS RUNNING UNDER SYSTEMD.
    #       THIS IS JUST AN EXAMPLE. YOU CAN WRITE YOUR OWN NODE PROBLEM PLUGIN ON DEMAND.

    OK=0
    NONOK=1
    UNKNOWN=2

    ntpStatus=1
    systemctl status ntpd.service | grep 'Active:' | grep -q running
    if [ $? -ne 0 ]; then
        ntpStatus=0
    fi

    chronydStatus=1
    systemctl status chronyd.service | grep 'Active:' | grep -q running
    if [ $? -ne 0 ]; then
        chronydStatus=0
    fi

    if [ $ntpStatus -eq 0 ] && [ $chronydStatus -eq 0 ]; then
        echo "NTP service is not running"
        exit $NONOK
    fi

    echo "NTP service is running"
    exit $OK

  instance_expired_checker.json: |
    {
      "plugin": "custom",
      "pluginConfig": {
        "invoke_interval": "600s",
        "timeout": "30s",
        "max_output_length": 80,
        "concurrency": 3,
        "enable_message_change_based_condition_update": false
      },
      "source": "instance_termination_custom_checker",
      "conditions": [
        {
          "type": "InstanceExpired",
          "reason": "InstanceNotToBeTerminated",
          "message": "instance is not going to be terminated"
        }
      ],
      "rules": [
        {
          "type": "temporary",
          "reason": "InstanceToBeTerminated",
          "path": "./config/plugin/instance_expired_checker.sh",
          "timeout": "30s"
        },
        {
          "type": "permanent",
          "condition": "InstanceExpired",
          "reason": "InstanceToBeTerminated",
          "path": "./config/plugin/instance_expired_checker.sh",
          "timeout": "30s"
        }
      ]
    }
  instance_expired_checker.sh: |
    #!/bin/bash
    OK=0
    NONOK=1
    UNKNOWN=2

    check_url='http://100.100.100.200/latest/meta-data/instance/spot/termination-time'
    for ((i=1; i<=5; i ++))
    do
      resp=$(curl --max-time 5 -s $check_url)
      if [ $? != 0 ]; then
        sleep 1
      else
        echo $resp
        date --date $resp +"%s"
        if [ $? != 0 ]; then
          exit $OK
        else
          echo "instance is going to be terminated at $resp"
          exit $NONOK
        fi
      fi
    done
    echo "curl $check_url exe fail after try 5 times"
    exit $OK

  ram-role-problem-monitor.json: |
    {
      "plugin": "custom",
      "pluginConfig": {
        "timeout": "60s",
        "invoke_interval": "600s",
        "concurrency": 3
      },
      "source": "ram-role-monitor",
      "conditions": [
        {
          "type": "RAMRoleError",
          "reason": "NodeHasRAMRole",
          "message": "node has ram role"
        }
      ],
      "rules": [
        {
          "type": "permanent",
          "condition": "RAMRoleError",
          "reason": "NodeHasNoRAMRole",
          "message": "node has no ram role",
          "path": "/config/plugin/check_ram-role.sh",
          "timeout": "60s"
        }
      ]
    }
  check_ram-role.sh: |
    #!/bin/bash
    # check node has ram-role
    OK=0
    NONOK=1
    UNKNOWN=2
    for ((i=1; i<=5; i ++))
    do
      ram_role=$(curl --max-time 5 http://100.100.100.200/latest/meta-data/ram/security-credentials/ )
      resp=$(curl --max-time 5 http://100.100.100.200/latest/meta-data/ram/security-credentials/$ram_role)
      found=$(echo $resp | grep "Success")
      if [[ "$found" != "" ]]; then
        echo "node has ram role"
        exit $OK
      fi
      sleep 5
    done
    echo "node has no ram role"
    exit $NONOK


  fd-problem-monitor.json: |
    {
      "plugin": "custom",
      "pluginConfig": {
        "invoke_interval": "120s",
        "timeout": "30s",
        "max_output_length": 80,
        "concurrency": 3
      },
      "source": "fd-custom-plugin-monitor",
      "conditions": [
        {
          "type": "FDPressure",
          "reason": "NodeHasNoFDPressure",
          "message": "node has no fd pressure"
        }
      ],
      "rules": [
        {
          "type": "permanent",
          "condition": "FDPressure",
          "reason": "NodeHasFDPressure",
          "message": "too many fds have been used",
          "path": "/config/plugin/check_fd.sh",
          "timeout": "30s"
        }
      ]
    }
  check_fd.sh: |
    #!/bin/bash
    # check max fd open files
    OK=0
    NONOK=1
    UNKNOWN=2

    cd /host/proc

    count=$(find -maxdepth 1 -type d -name '[0-9]*' | xargs -I {} ls {}/fd | wc -l)
    max=$(cat /host/proc/sys/fs/file-max)

    if [[ $count -gt $((max*80/100)) ]]; then
    echo "current fd usage is $count and max is $max"
    exit $NONOK
    fi
    echo "node has no fd pressure"
    exit $OK


  irqbalance-monitor.json: |
    {
      "plugin": "custom",
      "pluginConfig": {
        "timeout": "30s",
        "invoke_interval": "120s",
        "concurrency": 3
      },
      "source": "irqbalance-custom-plugin-monitor",
      "conditions": [
        {
          "type": "irqbalanceStatus",
          "reason": "irqbalanceOpen",
          "message": "node irqbalance service open"
        }
      ],
      "rules": [
        {
          "type": "permanent",
          "condition": "irqbalanceStatus",
          "reason": "irqbalanceClose",
          "message": "node close irqbalance",
          "path": "/config/plugin/check_irqbalance.sh",
          "timeout": "30s"
        }
      ]
    }
  check_irqbalance.sh: |
    #!/bin/bash
    OK=0
    NONOK=1
    UNKNOWN=2
    A=$(systemctl status irqbalance |grep "active (running)")
    if [[ $A != "" ]]; then
    echo "node open irqbalance service"
    exit $OK
    fi
    echo "node close irqbalance service"
    exit $NONOK


  public-network-problem-monitor.json: |
    {
      "plugin": "custom",
      "pluginConfig": {
        "timeout": "120s",
        "invoke_interval": "600s",
        "concurrency": 3
      },
      "source": "public-network-custom-plugin-monitor",
      "conditions": [
        {
          "type": "PublicNetworkError",
          "reason": "PublicNetworkOnline",
          "message": "node can connect to public network"
        }
      ],
      "rules": [
        {
          "type": "permanent",
          "condition": "PublicNetworkError",
          "reason": "PublicNetworkOffline",
          "message": "node can not connect to public network",
          "path": "/config/plugin/check_public_network.sh",
          "timeout": "120s"
        }
      ]
    }
  check_public_network.sh: |
    #!/bin/bash
    OK=0
    NONOK=1
    UNKNOWN=2
    IPLIST=("114.114.114.114" "223.5.5.5" "8.8.4.4")
    status=$NONOK
    for ip in "${IPLIST[@]}";
    do
      resp=$(echo |ping -t 10 -w 1 $ip|head -2)
      found=$(echo $resp | grep "64 bytes from $ip")
      if [[ "$found" != "" ]]; then
          echo "node can connect to public network"
          exit $OK
      fi
    done
    echo "node could not connect to public network"
    exit $NONOK


  nvidia-gpu-problem-monitor.json: |
    {
      "plugin": "custom",
      "pluginConfig": {
        "invoke_interval": "120s",
        "timeout": "90s",
        "max_output_length": 500,
        "concurrency": 3
      },
      "source": "nvidia-gpu-custom-plugin-monitor",
      "conditions": [
        {
          "type": "NvidiaXidError",
          "reason": "NodeHasNoNvidiaXidError",
          "message": "Node has no Nvidia Xid error occured"
        }
      ],
      "rules": [
        {
          "type": "permanent",
          "condition": "NvidiaXidError",
          "reason": "NodeHasNvidiaXidError",
          "message": "Nvidia Xid error has occured",
          "path": "/config/plugin/check_nvidia_gpu.sh",
          "timeout": "20s"
        }
      ]
    }
  check_nvidia_gpu.sh: |
    #!/bin/bash
    # check Nvidia Xid error in system log
    OK=0
    NONOK=1

    nvidia_info=$(lspci | grep -i nvidia)
    if [[ $nvidia_info == "" ]]; then
      exit $OK
    fi

    FOUND=0
    interval=120 # check latest messages within given time interval. Keep it same as plugin config.
    declare -a XIDS

    ts_uptime=`cut -d' ' -f1 </proc/uptime`
    ts_now=`date -u +%s`
    while read line; do
        ts_dmesg=$(echo "$line" | awk -F '[' '{print $2}' | awk -F ']' '{print $1}')
        ts_since_up=$(date -u -d"70-1-1 + $ts_now sec - $ts_uptime sec + $ts_dmesg sec" +"%s")
        past_time=$((ts_now - ts_since_up))
        time_dmesg=$(date -d"@$ts_since_up" +"%F %T")
        # echo "#### Found NVRM: Xid, "$past_time" seconds ago, @ "$ts_dmesg"=="$time_dmesg
        if ((past_time < interval)); then
            # echo "$line", eg:"[496617.457970] NVRM: Xid (PCI:0000:00:07): 43, Ch 00000018"
            tmp=${line#*NVRM:}
            tmp=${tmp%,*}
            xid=${tmp##*:}
            XIDS[$FOUND]=$xid
            ((FOUND++))
        fi
    done <<< "$(dmesg | grep -i 'NVRM: Xid')"

    if [[ $FOUND > 0 ]] ; then
        #echo "["$(date -d @$ts_now +"%F %T")"] $FOUND Nvidia Xid error occured in last $interval seconds! "
        for xid in ${XIDS[@]}; do
          if [ $xid == 13 ]; then
            echo "XID 13: GR: SW Notify Error."
          elif [ $xid == 31 ]; then
            echo "XID 31: Fifo: MMU Error."
          elif [ $xid == 32 ]; then
            echo "XID 32: PBDMA Error."
          elif [ $xid == 43 ]; then
            echo "XID 43: RESET CHANNEL VERIF ERROR."
          elif [ $xid == 45 ]; then
            echo "XID 45: OS: Preemptive Channel Removal."
          elif [ $xid == 48 ]; then
            echo "XID 48: DBE (Double Bit Error) ECC Error."
          else
            echo "XID $xid."
          fi
        done
        exit $NONOK
    fi
    echo "["$(date -d @$ts_now +"%F %T")"] No Nvidia Xid error occured."
    exit $OK


  check_ps_hang.sh: |
    #!/bin/sh

    OK=0
    NONOK=1
    UNKNOWN=2

    for f in `find /host/proc/*/task -name status`
    do
        checkD=$(cat $f|grep "State.*D")
        if [ $? -eq '0' ]; then
            cmdline=$(echo ${f%%status}"cmdline")
            pid=$(echo ${f%%status}"")
            timeout -s 9 2 cat $cmdline
            if [ $? -ne "0" ]; then
                echo "process $pid is in State D and lead to ps -ef process hang,"
                exit $NONOK
            fi
        fi
    done
    echo "ps -ef works"
    exit $OK
  ps-hang-problem-monitor.json: |
    {
      "plugin": "custom",
      "pluginConfig": {
        "invoke_interval": "600s",
        "timeout": "60s",
        "max_output_length": 80,
        "concurrency": 3,
        "enable_message_change_based_condition_update": false
      },
      "source": "ps-hang-custom-plugin-monitor",
      "conditions": [
        {
          "type": "PSProcessWorks",
          "reason": "PSProcessWorks",
          "message": "ps process works"
        }
      ],
      "rules": [
        {
          "type": "temporary",
          "reason": "PSProcessIsHung",
          "path": "./config/plugin/check_ps_hang.sh",
          "timeout": "60s"
        }
      ]
    }


  check_pid_pressure.sh: |
    #!/bin/sh

    OK=0
    NONOK=1
    UNKNOWN=2

    pidMax=$(cat /host/proc/sys/kernel/pid_max)
    threshold=85
    availablePid=$(($pidMax * $threshold / 100))
    activePid=$(ls /host/proc/ |grep  -e "[0-9]" |wc -l)
    if [ $activePid -gt $availablePid ]; then
        echo "Total running PIDs: $activePid, greater than $availablePid ($threshold% of pidMax $pidMax)"
        exit $NONOK
    fi

    echo "Has sufficient PID available"
    exit $OK
  pid-pressure-problem-monitor.json: |
    {
      "plugin": "custom",
      "pluginConfig": {
        "invoke_interval": "300s",
        "timeout": "60s",
        "max_output_length": 100,
        "concurrency": 3
      },
      "source": "pid-pressure-custom-plugin-monitor",
      "conditions": [
        {
          "type": "NodePIDPressure",
          "reason": "NodeHasNoPIDPressure",
          "message": "Node has no PID Pressure"
        }
      ],
      "rules": [
        {
          "type": "permanent",
          "condition": "NodePIDPressure",
          "reason": "NodeHasPIDPressure",
          "message": "node has no PID available",
          "path": "./config/plugin/check_pid_pressure.sh",
          "timeout": "20s"
        }
      ]
    }


  check_csi_hang.sh: |
    #!/bin/sh

    OK=0
    NONOK=1


    for pid in `ps -ef |grep plugin.csi.alibabacloud | awk '{print $2}'`
    do
        checkD=$(cat /host/proc/$pid/status |grep "State.*D")
        checkP=$(cat /host/proc/$pid/status |grep "Name.*plugin.csi")
        if [ "$checkP" != "" ] && [ "$checkD" != "" ]; then
            echo "process diskplugin.csi is in State D"
            exit $NONOK
        fi
    done

    echo "procss diskplugin.csi State ok"
    exit $OK
  csi-hang-problem-monitor.json: |
    {
      "plugin": "custom",
      "pluginConfig": {
        "invoke_interval": "600s",
        "timeout": "120s",
        "max_output_length": 80,
        "concurrency": 3,
        "enable_message_change_based_condition_update": false
      },
      "source": "csi-hang-custom-plugin-monitor",
      "conditions": [
        {
          "type": "CSIProcessWorks",
          "reason": "CSIProcessWorks",
          "message": "csi process works"
        }
      ],
      "rules": [
        {
          "type": "temporary",
          "reason": "CSIProcessIsHung",
          "path": "./config/plugin/check_csi_hang.sh",
          "timeout": "60s"
        }
      ]
    }


  check_inodes.sh: |
    #!/bin/bash
    # check inode utilization on block device of mounting point /
    OK=0
    NONOK=1
    UNKNOWN=2

    iuse=$(df -i | grep "/$" | grep -e [0-9]*% -o | tr -d %)

    if [[ $iuse -gt 80 ]]; then
    echo "current inode usage is over 80% on node"
    exit $NONOK
    fi
    echo "node has no inode pressure"
    exit $OK
  inodes-problem-monitor.json: |
    {
      "plugin": "custom",
      "pluginConfig": {
        "invoke_interval": "120s",
        "timeout": "30s",
        "max_output_length": 80,
        "concurrency": 3
      },
      "source": "inodes-custom-plugin-monitor",
      "conditions": [
        {
          "type": "InodesPressure",
          "reason": "NodeHasNoInodesPressure",
          "message": "node has no inodes pressure"
        }
      ],
      "rules": [
        {
          "type": "permanent",
          "condition": "InodesPressure",
          "reason": "NodeHasInodesPressure",
          "message": "inodes usage is over 80% on /dev/sda",
          "path": "/config/plugin/check_inodes.sh"
        }
      ]
    }


  network_problem.sh: |
    #!/bin/bash

    # This plugin checks for common network issues.
    # Currently only checks if conntrack table is more than 90% used.

    readonly OK=0
    readonly NONOK=1
    readonly UNKNOWN=2

    # "nf_conntrack" replaces "ip_conntrack" - support both
    readonly NF_CT_COUNT_PATH='/host/proc/sys/net/netfilter/nf_conntrack_count'
    readonly NF_CT_MAX_PATH='/host/proc/sys/net/netfilter/nf_conntrack_max'
    readonly IP_CT_COUNT_PATH='/host/proc/sys/net/ipv4/netfilter/ip_conntrack_count'
    readonly IP_CT_MAX_PATH='/host/proc/sys/net/ipv4/netfilter/ip_conntrack_max'

    if [[ -f $NF_CT_COUNT_PATH ]] && [[ -f $NF_CT_MAX_PATH ]]; then
      readonly CT_COUNT_PATH=$NF_CT_COUNT_PATH
      readonly CT_MAX_PATH=$NF_CT_MAX_PATH
    elif [[ -f $IP_CT_COUNT_PATH ]] && [[ -f $IP_CT_MAX_PATH ]]; then
      readonly CT_COUNT_PATH=$IP_CT_COUNT_PATH
      readonly CT_MAX_PATH=$IP_CT_MAX_PATH
    else
      exit $UNKNOWN
    fi

    readonly conntrack_count=$(< $CT_COUNT_PATH) || exit $UNKNOWN
    readonly conntrack_max=$(< $CT_MAX_PATH) || exit $UNKNOWN
    readonly conntrack_usage_msg="${conntrack_count} out of ${conntrack_max}"

    if (( conntrack_count > conntrack_max * 9 /10 )); then
      echo "Conntrack table usage over 90%: ${conntrack_usage_msg}"
      exit $NONOK
    else
      echo "Conntrack table usage: ${conntrack_usage_msg}"
      exit $OK
    fi
  network-problem-monitor.json: |
    {
      "plugin": "custom",
      "pluginConfig": {
        "invoke_interval": "30s",
        "timeout": "5s",
        "max_output_length": 80,
        "concurrency": 3
      },
      "source": "network-custom-plugin-monitor",
      "metricsReporting": true,
      "conditions": [],
      "rules": [
        {
          "type": "temporary",
          "reason": "ConntrackFull",
          "path": "/config/plugin/network_problem.sh",
          "timeout": "3s"
        }
      ]
    }


  check_docker_offline.sh: |
    #!/bin/bash

    OK=0
    NONOK=1
    UNKNOWN=2

    # check docker offline

    # check dockerd containerd service exist
    systemctl list-units --type=service -a | grep -E -q 'docker|containerd'
    if [ $? -ne 0 ]; then
        echo "node not install docker or containerd"
        exit ${UNKNOWN}
    fi

    # check dockerd status
    systemctl list-units --type=service -a | grep -q docker
    if [ $? -eq 0 ]; then
        echo "node have dockerd service"
        curl --connect-timeout 20 -m 20 --unix-socket /var/hostrun/docker.sock http:/containers/json >/dev/null 2>&1
        if [[ $? -ne 0 ]]; then
            echo "docker ps check error"
            exit ${NONOK}
        fi
    fi

    # check containerd status
    systemctl list-units --type=service -a | grep -q containerd
    if [ $? -eq 0 ]; then
        echo "node have containerd service"
        CONTAINERD_STATUS=`systemctl status containerd | grep Active | awk '{print $3}' | cut -d "(" -f2 | cut -d ")" -f1`
        echo $CONTAINERD_STATUS
        if [[ "$CONTAINERD_STATUS"x != "runningx" ]]; then
            echo "containerd ps check error"
            exit ${NONOK}
        fi
    fi

    exit ${OK}
  docker-offline-monitor.json: |
    {
      "plugin": "custom",
      "pluginConfig": {
      "invoke_interval": "30s",
      "timeout": "30s",
      "max_output_length": 80,
        "concurrency": 3
      },
      "source": "docker-offline-custom-plugin-monitor",
      "conditions": [
        {
          "type": "DockerOffline",
          "reason": "DockerDaemonNotOffline",
          "message": "docker daemon is ok"
        }
      ],
      "rules": [
        {
          "type": "permanent",
          "condition": "DockerOffline",
          "reason": "docker daemon is offline",
          "path": "/config/plugin/check_docker_offline.sh",
          "timeout": "25s"
        }
      ]
    }

# The following are from ASI rule base
# 2022.7.1 remove CPUPressure
#        {
#          "type": "Node.CPUPressure",
#          "reason": "CPULoadOK",
#          "message": "CPU load is ok"
#        },
#        {
#          "type": "permanent",
#          "condition": "Node.CPUPressure",
#          "reason": "CPULoadTooHigh",
#          "path": "/config/plugin/check_cpu_load.sh",
#          "timeout": "60s"
#        },
  system-custom-plugin-monitor.json: |
    {
      "plugin": "custom",
      "pluginConfig": {
      "invoke_interval": "600s",
      "timeout": "60s",
      "max_output_length": 1000,
      "concurrency": 3
      },
      "source": "system-custom-plugin-monitor.json",
      "conditions": [

        {
          "type": "Node.IOPressureOK",
          "reason": "CPULoadOK",
          "message": "CPU load is ok"
        },
        {
          "type": "Node.IOHang",
          "reason": "IOHangOK",
          "message": "IO hang is not happening"
        }
      ],
      "rules": [
        {
          "type": "permanent",
          "condition": "Node.IOPressureOK",
          "reason": "IOPressure",
          "path": "/config/plugin/check_io_health.sh",
          "timeout": "60s"
        },
        {
          "type": "permanent",
          "condition": "Node.IOHang",
          "reason": "IOHang",
          "path": "/config/plugin/check_io_hang.sh",
          "timeout": "60s"
        }
      ]
    }
  check_cpu_load.sh: |
    #!/bin/bash

    OK=0
    NONOK=1
    UNKNOWN=2

    consistency=0
    errMsg=""

    # 整机load异常
    loadThresholdTimes=12
    loadThreshold=$(( $(grep '^cpu cores' /proc/cpuinfo | uniq | awk '{print $4}') * loadThresholdTimes ))

    output() {
      if [[ ${consistency} -eq 0 ]]; then
        echo "load is normal"
        exit ${OK}
      elif [[ ${consistency} -eq 1 ]]; then
        echo ${errMsg}
        exit ${NONOK}
      else
        echo ${errMsg}
        exit ${UNKNOWN}
      fi
    }

    # check load
    load=$(uptime | awk -F'[ ,]' '{print $16}')
    if [[ $(echo "${loadThreshold} < $(uptime | awk -F'[ ,]' '{print $16}')" | bc) -eq 1 ]]; then
      consistency=1
      errMsg="load is too high: ${load}"
      output
    fi

    output

  check_io_health.sh: |
    #!/bin/bash

    source "$(cd $(dirname $0)/..;pwd)/lib/lib.sh"

    consistency=0
    errMsg=""

    # IO util持续高 IO await持续高

    output() {
      if [[ ${consistency} -eq 0 ]]; then
        echo "io is all normal"
        exit ${OK}
      elif [[ ${consistency} -eq 1 ]]; then
        echo ${errMsg}
        exit ${NONOK}
      else
        echo ${errMsg}
        exit ${UNKNOWN}
      fi
    }

    blkids=$(blkid)

    check_io_result() {
      ioCheckResult="$1"
      if [[ -n "$ioCheckResult" ]]; then
        while IFS= read -r line; do
          dev=$(echo $line | awk '{print $1}')        # check mounted devices only
          if [[ "$blkids" == *"$dev"* ]]; then
              ioCheckResult2=${ioCheckResult2}${line}
          fi
        done <<< "$ioCheckResult"

        if [[ -n "$ioCheckResult2" ]]; then
          consistency=1
          errMsg=$ioCheckResult2
        fi
      fi
    }

    # check io util
    ioStatResult=$(iostat -dx 1 5)
    ioUtilResult=$(echo "${ioStatResult}" | awk '$1=="Device:"{count++;next}
      NF&&count>1&&count<5{utilSum[$1]+=$14}
      END{
        for (device in utilSum)
          {
            utilAvg=utilSum[device]/3
            if (utilAvg>90)
              printf "%s util: %s; \n", device, utilAvg
          }
      }'
    )

    check_io_result "$ioUtilResult"

    # check io await
    ioAwaitResult=$(echo "${ioStatResult}" | awk '$1=="Device:"{count++;next}
      NF&&count>1&&count<5{awaitSum[$1]+=$10}
      END{
        for (device in awaitSum)
          {
            awaitAvg=awaitSum[device]/3
            if (awaitAvg>200)
              printf "%s await: %s; \n", device, awaitAvg
          }
      }'
    )

    check_io_result "$ioAwaitResult"

    output


  check_io_hang.sh: |
    #!/bin/bash

    source "$(cd "$(dirname "$0")/.." || exit 0;pwd)/lib/lib.sh"

    consistency=0
    errMsg=""

    # io hang check

    output() {
      if [[ ${consistency} -eq 0 ]]; then
        echo "io is all normal"
        exit ${OK}
      elif [[ ${consistency} -eq 1 ]]; then
        echo "${errMsg}"
        exit ${NONOK}
      else
        echo "${errMsg}"
        exit ${UNKNOWN}
      fi
    }

    # 检测原理为读取内核新增文件
    # https://aone.alibaba-inc.com/req/29316828

    devices=$(ls /sys/block/)
    ioHangResult=""
    kernelVersion=$(uname -r)
    # Buggy Versions: 4.19.91-006, 4.19.91-007
    buggyVersion="4\.19\.91-00[67]\.\S+"

    for device in ${devices}
    do
      if [[ ${kernelVersion} =~ ${buggyVersion} && ! -d /sys/block/"${device}"/mq ]]; then
        continue
      fi
      if [[ -f /sys/block/"${device}"/hang ]]; then
        ioResult=$(awk '{print $1,$2}' < /sys/block/"${device}"/hang)
        read -r ioReadHang ioWriteHang <<< "$ioResult"
        # echo "${ioReadHang}${ioWriteHang}"
        if [[ ${ioReadHang} -ne 0 ]]; then
          consistency=1
          ioHangResult=${ioHangResult}"${device} ioReadHang=${ioReadHang} "
        fi
        if [[ ${ioWriteHang} -ne 0 ]]; then
          consistency=1
          ioHangResult=${ioHangResult}"${device} ioWriteHang=${ioWriteHang} "
        fi
      fi
    done

    if [[ ${consistency} -eq 1 ]]; then
      errMsg=${ioHangResult}
    fi

    output


  kubelet-custom-plugin-monitor.json: |
    {
      "plugin": "custom",
      "pluginConfig": {
        "invoke_interval": "600s",
        "timeout": "600s",
        "max_output_length": 1000,
        "concurrency": 3
      },
      "source": "kubelet-custom-plugin-monitor",
      "metricsReporting": true,
      "conditions": [
        {
          "type": "Kubelet.ClosedNetworkConn",
          "reason": "KubeletHasNoClosedNetworkConnIssue",
          "message": "kubelet has no closed network connection issue"
        }
      ],
      "rules": [
        {
          "type": "permanent",
          "condition": "Kubelet.ClosedNetworkConn",
          "reason": "ClosedNetworkConnectionBug",
          "path": "/config/plugin/check_kubelet_closed_network.sh",
          "timeout": "60s"
        }
      ]
    }
  check_kubelet_closed_network.sh: |
    #!/usr/bin/env bash

    # shellcheck source=custom/plugins/lib/lib.sh
    source "$(cd "$(dirname $0)/.." || exit 0; pwd)/lib/lib.sh"

    if [[ ! -f "/home/t4/kubernetes/logs/kubelet.ERROR" ]]; then
        exit "${OK}"
    fi

    timestamp="E$(date '+%m%d %H'):"
    if (( $(tail -n 10000 /home/t4/kubernetes/logs/kubelet.ERROR | grep "$timestamp" | grep -c "use of closed network connection") > 1 )); then
        echo "kubelet golang http bug occur"
        exit "${NONOK}"
    fi

    exit "${OK}"


  container-custom-plugin-monitor.json: |
    {
      "plugin": "custom",
      "pluginConfig": {
        "invoke_interval": "600s",
        "timeout": "600s",
        "max_output_length": 1000,
        "concurrency": 3
      },
      "source": "container-custom-plugin-monitor",
      "metricsReporting": true,
      "conditions": [
        {
          "type": "Container.NetDown",
          "reason": "ContainerNetIsOK",
          "message": "Container Network is OK"
        },
        {
          "type": "Container.IpDuplicate",
          "reason": "NoIpDuplicate",
          "message": "IP is not duplicate"
        },
        {
          "type": "Container.LogPermission",
          "reason": "LogDirectoryPermissionIsOK",
          "message": "/var/log directory permission is 755"
        }
      ],
      "rules": [
        {
          "type": "permanent",
          "condition": "Container.NetDown",
          "reason": "ContainerNetIsDown",
          "path": "/config/plugin/check_container_net.sh",
          "timeout": "60s"
        },
        {
          "type": "permanent",
          "condition": "Container.IpDuplicate",
          "reason": "IpDuplicate",
          "path": "/config/plugin/check_ip_duplicate.sh",
          "timeout": "60s"
        },
        {
          "type": "permanent",
          "condition": "Container.LogPermission",
          "reason": "LogDirectoryPermissionUnhealthy",
          "path": "/config/plugin/check_log_directory_permission.sh",
          "timeout": "60s"
        }
      ]
    }
  check_container_net.sh: |
    #!/bin/bash

    source "$(cd $(dirname $0)/..;pwd)/lib/lib.sh"

    # NOTE: THIS SCRIPT IS TO CHECK NETWORK IN CONTAINER

    cmd=$(daemon_type)
    if [[ -z ${cmd} ]] || [[ "${cmd}" == "containerd" ]]; then
      echo "unsupported daemon type: ${cmd}"
      exit ${OK}
    fi

    get_netns_pid() {
      echo "$(lsns -t net | grep -v "qemu-kvm" | grep -v "PID" | awk '{print $4}' | grep -w -v "1")"
    }

    run() {
      local netns_pid=$(get_netns_pid)

      hostIp=$(hostname -i | head -n 1)
      if ! [[ ${hostIp} =~ ^[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}$ ]]; then
        hostIp=$(hostname -i | tail -n 1)
      fi

      for pid in ${netns_pid}; do
        if [[ ! -e /proc/${pid}/ns/net ]]; then
          continue
        fi
        nsenter --net=/proc/${pid}/ns/net -F -- ping -c 1 -W 1 ${hostIp} &>/dev/null
        if [[ $? -ne 0 ]]; then
          echo "/proc/${pid}/ns/net network disconnected"
          return ${NONOK}
        fi
      done

      # check all netns file
      for netns in $(find /var/run/netns/ -name "cni-*"); do
        nsenter --net=${netns} -F -- ping -c 1 -W 1 ${hostIp} &>/dev/null
        if [[ $? -ne 0 ]]; then
          grep ${netns} /home/t4/pouch/containers/*/*.json -r | grep -qE "io.containerd.rund.v2|io.containerd.kata.v2"
          if [[ $? -ne 0 ]]; then
            echo "${netns} network disconnected"
            return ${NONOK}
          fi
        fi
      done
    }

    run

    if [[ $? -ne 0 ]]; then
      exit ${NONOK}
    fi

    echo "Container Network is OK"
    exit ${OK}
  check_ip_duplicate.sh: |
    #!/bin/bash

    get_netns_pid() {
      echo "$(lsns -t net -o PID | grep -v "PID" | grep -v -w "1")"
    }

    main() {
      local state=0
      local netns_pid=$(get_netns_pid)
      local ip_list=""

      for pid in ${netns_pid}; do
        ipmask=$(nsenter --net=/proc/${pid}/ns/net -F -- \
              ip -o -4 addr show dev eth0 scope global | awk '{print $4}')
        if [[ -z "${ipmask}" ]]; then
          continue
        fi

        echo "${ip_list}" | grep -qw "${ipmask}"
        if [[ $? -eq 0 ]]; then
          # Duplicate IP
          state=1
        else
          ip_list="${ip_list} ${ipmask}"
        fi
      done

      if [[ ${state} -eq 0 ]]; then
        echo "IP is not duplicate"
        exit ${OK}
      else
        echo "IP is duplicate"
        exit ${NONOK}
      fi
    }

    main
  check_log_directory_permission.sh: |
    #!/bin/bash

    # shellcheck source=custom/plugins/lib/lib.sh
    source "$(cd "$(dirname $0)/.." || exit 0; pwd)/lib/lib.sh"

    msg="check container /var/log permission is ok"

    run() {
      daemon=$(daemon_type)
      if [[ -z ${daemon} ]]; then
        msg="not install container daemon"
        return ${UNKNOWN}
      fi

      if [[ "${daemon}" != "pouch" ]]; then
        msg="only support pouch-container"
        return ${OK}
      fi

      containers=$(pouch ps | grep k8s_main | awk '{print $2}')
      for cid in ${containers}; do
        host_dir=$(pouch inspect ${cid} | grep ":/var/log\"\," | awk -F \: '{print $1}' | awk -F \" '{print $2}')
        if [[ -z ${host_dir} ]]; then
          continue
        fi

        permission=$(stat -c %a ${host_dir})
        if [[ $? -ne 0 ]]; then
          continue
        fi

        if [[ "${permission}" != "755" ]]; then
          msg="${cid} /var/log permission is ${permission}"
          return ${NONOK}
        fi
      done
    }

    run
    ret=$?

    echo "${msg}"

    exit ${ret}

  lib.sh: |
    OK=0
    NONOK=1
    UNKNOWN=2

    daemon_type() {
      rpm -q pouch-container > /dev/null 2>&1
      if [[ $? -eq 0 ]]; then
        echo "pouch"
        return
      fi

      rpm -q alidocker > /dev/null 2>&1
      if [[ $? -eq 0 ]]; then
        echo "docker"
        return
      fi

      rpm -q pouch-containerd > /dev/null 2>&1
      if [[ $? -eq 0 ]]; then
        echo "containerd"
        return
      fi

      if [[ -e "/usr/local/bin/pouchd" ]]; then
        echo "pouch"
        return
      fi

      if [[ -e "/usr/bin/dockerd" ]]; then
        echo "docker"
        return
      fi

      if [[ ! -e "/usr/local/bin/pouchd" ]] && [[ -e "/usr/local/bin/containerd" ]];then
        echo "containerd"
        return
      fi

      return
    }

    # 满足检测脚本传入label_selector 圈定本机是否需要执行检测
    function check_label() {
        if [[ -z $1 ]]; then
          echo ${UNKNOWN}
          return
        fi

        if [[ -f ${lib_path}/node_selector.py ]]; then
          contain_label=$(python "${lib_path}/node_selector.py" "$1")
          # 匹配到label表明该机被圈定
          if [[ ${contain_label} == "match" ]]; then
             echo ${OK}
             return
          fi
          # 未匹配到
          echo ${NONOK}
          return
        fi
        # 未执行 selector
        echo ${UNKNOWN}
        return
    }
kind: ConfigMap
metadata:
  name: node-problem-detector-config
  namespace: kube-system